{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>filter_title</th>\n",
       "      <th>filter_title_no_stops</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>we want to talk about our marriage</td>\n",
       "      <td>want talk marriage</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>the trump presidency last week tonight with jo...</td>\n",
       "      <td>trump presidency last week tonight john oliver...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>racist superman rudy mancuso king bach lele pons</td>\n",
       "      <td>racist superman rudy mancuso king bach lele pons</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>nickelback lyrics real or fake</td>\n",
       "      <td>nickelback lyrics real fake</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>i dare you going bald</td>\n",
       "      <td>dare going bald</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE   \n",
       "1  The Trump Presidency: Last Week Tonight with J...   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...   \n",
       "3                   Nickelback Lyrics: Real or Fake?   \n",
       "4                           I Dare You: GOING BALD!?   \n",
       "\n",
       "                                        filter_title  \\\n",
       "0                 we want to talk about our marriage   \n",
       "1  the trump presidency last week tonight with jo...   \n",
       "2   racist superman rudy mancuso king bach lele pons   \n",
       "3                     nickelback lyrics real or fake   \n",
       "4                              i dare you going bald   \n",
       "\n",
       "                               filter_title_no_stops     category_id  \n",
       "0                                 want talk marriage  People & Blogs  \n",
       "1  trump presidency last week tonight john oliver...   Entertainment  \n",
       "2   racist superman rudy mancuso king bach lele pons          Comedy  \n",
       "3                        nickelback lyrics real fake   Entertainment  \n",
       "4                                    dare going bald   Entertainment  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titles_info = pd.read_csv('./output/US_count_vectorizer_dataset.csv')\n",
    "df_titles_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_titles_info['filter_title']\n",
    "df_y = df_titles_info['category_id']\n",
    "\n",
    "df_titles_info.to_csv('./output/US_count_vectorizer_dataset.csv', index=False)\n",
    "\n",
    "target_names = list(df_titles_info['category_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32759, 10574)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "train_count_vector = count_vectorizer.fit_transform(x_train)\n",
    "test_count_vector = count_vectorizer.transform(x_test)\n",
    "print(train_count_vector.shape)\n",
    "# print(count_vectorizer.vocabulary_)\n",
    "print(train_count_vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32759, 10574)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfTransformer()\n",
    "x_trained_tfidf_vector = tfidf_vectorizer.fit_transform(train_count_vector)\n",
    "x_test_tfidf_vector = tfidf_vectorizer.transform(test_count_vector)\n",
    "print(x_trained_tfidf_vector.shape)\n",
    "# print(count_vectorizer.vocabulary_)\n",
    "print(x_trained_tfidf_vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tfidf = MultinomialNB().fit(x_trained_tfidf_vector, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.860927960927961\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       People & Blogs       1.00      0.20      0.33        91\n",
      "        Entertainment       0.92      0.77      0.84       664\n",
      "               Comedy       0.98      0.79      0.88       329\n",
      " Science & Technology       0.72      0.97      0.82      2016\n",
      "     Film & Animation       0.99      0.75      0.86       495\n",
      "      News & Politics       1.00      0.59      0.74       149\n",
      "               Sports       0.89      0.91      0.90       823\n",
      "                Music       0.91      0.96      0.93      1245\n",
      "       Pets & Animals       0.96      0.85      0.90       523\n",
      "            Education       0.00      0.00      0.00        10\n",
      "        Howto & Style       0.96      0.72      0.82       660\n",
      "     Autos & Vehicles       0.99      0.77      0.87       186\n",
      "      Travel & Events       0.91      0.84      0.87       461\n",
      "               Gaming       1.00      0.57      0.73        14\n",
      "Nonprofits & Activism       0.94      0.94      0.94       437\n",
      "                Shows       1.00      0.40      0.57        87\n",
      "\n",
      "             accuracy                           0.86      8190\n",
      "            macro avg       0.89      0.69      0.75      8190\n",
      "         weighted avg       0.88      0.86      0.86      8190\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loc/anaconda3/envs/yt-trends/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_tfidf = clf_tfidf.predict(x_test_tfidf_vector)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, pred_tfidf))\n",
    "print(metrics.classification_report(y_test, pred_tfidf, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_count = MultinomialNB().fit(train_count_vector, y_train)\n",
    "pred_count = clf_count.predict(test_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8996336996336997\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "       People & Blogs       0.93      0.75      0.83        91\n",
      "        Entertainment       0.91      0.82      0.86       664\n",
      "               Comedy       0.91      0.95      0.93       329\n",
      " Science & Technology       0.89      0.89      0.89      2016\n",
      "     Film & Animation       0.93      0.88      0.90       495\n",
      "      News & Politics       0.96      0.89      0.92       149\n",
      "               Sports       0.85      0.92      0.89       823\n",
      "                Music       0.92      0.96      0.94      1245\n",
      "       Pets & Animals       0.92      0.93      0.92       523\n",
      "            Education       1.00      0.20      0.33        10\n",
      "        Howto & Style       0.91      0.83      0.87       660\n",
      "     Autos & Vehicles       0.94      0.89      0.91       186\n",
      "      Travel & Events       0.87      0.92      0.89       461\n",
      "               Gaming       1.00      0.86      0.92        14\n",
      "Nonprofits & Activism       0.88      0.96      0.92       437\n",
      "                Shows       1.00      0.86      0.93        87\n",
      "\n",
      "             accuracy                           0.90      8190\n",
      "            macro avg       0.93      0.84      0.87      8190\n",
      "         weighted avg       0.90      0.90      0.90      8190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test, pred_count))\n",
    "print(metrics.classification_report(y_test, pred_count, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
